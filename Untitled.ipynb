{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU' : 1, 'CPU':16})\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "import random\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tongue_left': 0, 'lips_pipe': 1, 'tongue_up': 2, 'lips_smile_teeth': 3, 'tongue_down': 4, 'tongue_right': 5}\n"
     ]
    }
   ],
   "source": [
    "cascade = cv2.CascadeClassifier('./weights/haarcascade_frontalface_alt.xml')\n",
    "size = 128\n",
    "\n",
    "import pickle as pk\n",
    "import sys\n",
    "\n",
    "def disp_to_term(msg):\n",
    "    sys.stdout.write(msg + '\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def load_pickle(filename):\n",
    "    try:\n",
    "        p = open(filename, 'r')\n",
    "    except IOError:\n",
    "        print(\"Pickle file cannot be opened.\")\n",
    "        return None\n",
    "    try:\n",
    "        picklelicious = pk.load(p)\n",
    "    except ValueError:\n",
    "        print('load_pickle failed once, trying again')\n",
    "        p.close()\n",
    "        p = open(filename, 'r')\n",
    "        picklelicious = pk.load(p)\n",
    "\n",
    "    p.close()\n",
    "    return picklelicious\n",
    "\n",
    "def save_pickle(data_object, filename):\n",
    "    pickle_file = open(filename, 'w')\n",
    "    pk.dump(data_object, pickle_file)\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, nc, ngf, ndf, latent_variable_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.ngf = ngf\n",
    "        self.ndf = ndf\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "\n",
    "        # encoder\n",
    "        self.e1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "\n",
    "        self.e2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "\n",
    "        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
    "\n",
    "        self.e4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.fc1 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "        self.fc2 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "\n",
    "        # decoder\n",
    "        self.d1 = nn.Linear(latent_variable_size, ngf*8*2*4*4)\n",
    "\n",
    "        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd1 = nn.ReplicationPad2d(1)\n",
    "        self.d2 = nn.Conv2d(ngf*8*2, ngf*8, 3, 1)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8, 1.e-3)\n",
    "\n",
    "        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd2 = nn.ReplicationPad2d(1)\n",
    "        self.d3 = nn.Conv2d(ngf*8, ngf*4, 3, 1)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*4, 1.e-3)\n",
    "\n",
    "        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd3 = nn.ReplicationPad2d(1)\n",
    "        self.d4 = nn.Conv2d(ngf*4, ngf*2, 3, 1)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*2, 1.e-3)\n",
    "\n",
    "        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd4 = nn.ReplicationPad2d(1)\n",
    "        self.d5 = nn.Conv2d(ngf*2, ngf, 3, 1)\n",
    "        self.bn9 = nn.BatchNorm2d(ngf, 1.e-3)\n",
    "\n",
    "        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd5 = nn.ReplicationPad2d(1)\n",
    "        self.d6 = nn.Conv2d(ngf, nc, 3, 1)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n",
    "        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n",
    "        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n",
    "        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n",
    "        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n",
    "        h5 = h5.view(-1, self.ndf*8*4*4)\n",
    "\n",
    "        return self.fc1(h5), self.fc2(h5)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if 1:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h1 = self.relu(self.d1(z))\n",
    "        h1 = h1.view(-1, self.ngf*8*2, 4, 4)\n",
    "        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n",
    "        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n",
    "        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n",
    "        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n",
    "\n",
    "        return self.sigmoid(self.d6(self.pd5(self.up5(h5))))\n",
    "\n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(z)\n",
    "        return res, mu, logvar\n",
    "\n",
    "\n",
    "def get_facial_landmark_model(path):\n",
    "    model = VAE(nc=3, ngf=128, ndf=128, latent_variable_size=500)\n",
    "    model.load_state_dict(torch.load('/home/apletea/Downloads/sign/neunets/video_classification/weights/cpu_Epoch_28_Train_loss_25425.9503_Test_loss_25172.4120(3).pth'))\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "\n",
    "def get_seq_model():\n",
    "    model =  Sequential()\n",
    "    model.add(((LSTM(256,dropout=0.2,input_shape=(200,1000), return_sequences = True, stateful = False))))\n",
    "    model.add((LSTM(512,dropout=0.2,return_sequences = False )))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(6))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_video_features(stream,model):\n",
    "    X = []\n",
    "    while True:\n",
    "        _,img = stream.read()\n",
    "        if (_== False):\n",
    "            break\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        if (len(faces) == 0):\n",
    "            continue\n",
    "        #выделение лица\n",
    "        x,y,w,h = faces[0]\n",
    "        img = img[y:y+h+10, x:x+w+10]\n",
    "        img = cv2.resize(img,(size,size))\n",
    "        img = cv2.resize(img, (128,128))\n",
    "        img = np.transpose(img,(2,0,1))\n",
    "        img = np.expand_dims(img, axis=0) / 255\n",
    "        #тепловая карта лэндмарок на лице\n",
    "        #тут можно пробовать другие модели/автокодировщик/или нормальный facial landmark но я наткой не нашёл\n",
    "        b    = model.encode(torch.Tensor(img).cuda())\n",
    "        var  = b[0].cpu().detach().numpy()\n",
    "        mean = b[1].cpu().detach().numpy()\n",
    "        features = np.concatenate([var,mean])\n",
    "        features = np.array(features)\n",
    "        X.append(features)\n",
    "    return X\n",
    "\n",
    "cls_names = os.listdir('./tongue-detection/')\n",
    "class_ids = {cls_names[i]:i for i in range(len(cls_names))}\n",
    "print(class_ids)\n",
    "\n",
    "def get_DATA(path_to_folder,model):\n",
    "    X = []\n",
    "    y = []\n",
    "    for sign in os.listdir(path_to_folder):\n",
    "        for file in tqdm.tqdm(os.listdir(os.path.join(path_to_folder,sign))):\n",
    "            vs = cv2.VideoCapture('{}/{}/{}'.format(path_to_folder,sign,file))\n",
    "            vs_features = get_video_features(vs,model)\n",
    "            if (len(vs_features) == 0):\n",
    "                print ('skip')\n",
    "                continue\n",
    "            X.append(vs_features)\n",
    "            y.append(class_ids[sign])\n",
    "    return X,y\n",
    "\n",
    "def save_as_h5(name, features,labels):\n",
    "    with h5py.File(name, \"w\") as f:\n",
    "        f.create_dataset(\"features\", data=features)\n",
    "        f.create_dataset(\"labels\", data=labels)\n",
    "        \n",
    "def get_saved(path):\n",
    "    val = h5py.File(path, 'r')\n",
    "    val_features = val[\"features\"][: ]\n",
    "    val_labels = val[\"labels\"][: ]\n",
    "    return val_features, val_labels\n",
    "\n",
    "def plot(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('acc.png')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('loss.png')\n",
    "    \n",
    "def scheduler(epoch):\n",
    "    if epoch < 40:\n",
    "        return (.001)\n",
    "    elif epoch < 80:\n",
    "        return (.0001)\n",
    "    else:\n",
    "        return (.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = get_facial_landmark_model('./weights/faces.h5')\n",
    "#X,Y = get_DATA('./tongue-detection/', model)\n",
    "#train_features,test_features,train_labels,test_labels = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "#fit_features = sequence.pad_sequences(train_features,maxlen=200, dtype='float32')\n",
    "#predict_features = sequence.pad_sequences(test_features, maxlen=200,dtype='float32') \n",
    "#train_labels = to_categorical(train_labels)\n",
    "#test_labels = to_categorical(test_labels)\n",
    "save_as_h5('features_train.h5',fit_features,train_labels)\n",
    "save_as_h5('features_test.h5',predict_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_features,train_labels = get_save('features_train.h5')\n",
    "#predict_features,test_labels = get_save('features_test.h5')\n",
    "seq_m = get_seq_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 200, 1000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_features = np.reshape(predict_features, (68,200,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 608 samples, validate on 68 samples\n",
      "Epoch 1/160\n",
      "608/608 [==============================] - 22s 36ms/step - loss: 2.0993 - acc: 0.1546 - val_loss: 1.7776 - val_acc: 0.2059\n",
      "Epoch 2/160\n",
      "608/608 [==============================] - 13s 22ms/step - loss: 1.9459 - acc: 0.1743 - val_loss: 1.7851 - val_acc: 0.1765\n",
      "Epoch 3/160\n",
      "608/608 [==============================] - 13s 22ms/step - loss: 1.8943 - acc: 0.1727 - val_loss: 1.7997 - val_acc: 0.1176\n",
      "Epoch 4/160\n",
      "608/608 [==============================] - 13s 22ms/step - loss: 1.8669 - acc: 0.1776 - val_loss: 1.7866 - val_acc: 0.2500\n",
      "Epoch 5/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.8459 - acc: 0.1793 - val_loss: 1.7872 - val_acc: 0.1912\n",
      "Epoch 6/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.8112 - acc: 0.2007 - val_loss: 1.7749 - val_acc: 0.1471\n",
      "Epoch 7/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.7999 - acc: 0.1875 - val_loss: 1.8091 - val_acc: 0.1471\n",
      "Epoch 8/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.7727 - acc: 0.2204 - val_loss: 1.7451 - val_acc: 0.2500\n",
      "Epoch 9/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.7625 - acc: 0.2484 - val_loss: 1.7351 - val_acc: 0.2059\n",
      "Epoch 10/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.7054 - acc: 0.2632 - val_loss: 1.6991 - val_acc: 0.2059\n",
      "Epoch 11/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 1.7152 - acc: 0.2418 - val_loss: 1.6905 - val_acc: 0.3235\n",
      "Epoch 12/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 1.6857 - acc: 0.2796 - val_loss: 1.6433 - val_acc: 0.2500\n",
      "Epoch 13/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.6870 - acc: 0.2829 - val_loss: 1.6887 - val_acc: 0.2059\n",
      "Epoch 14/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.6477 - acc: 0.3026 - val_loss: 1.5818 - val_acc: 0.2941\n",
      "Epoch 15/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.6335 - acc: 0.3109 - val_loss: 1.5744 - val_acc: 0.2794\n",
      "Epoch 16/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 1.6041 - acc: 0.3224 - val_loss: 1.5107 - val_acc: 0.3676\n",
      "Epoch 17/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 1.5789 - acc: 0.3602 - val_loss: 1.4998 - val_acc: 0.3676\n",
      "Epoch 18/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 1.5703 - acc: 0.3174 - val_loss: 1.4713 - val_acc: 0.3235\n",
      "Epoch 19/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 1.4473 - acc: 0.4079 - val_loss: 1.4471 - val_acc: 0.2794\n",
      "Epoch 20/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 1.5313 - acc: 0.4128 - val_loss: 1.4616 - val_acc: 0.3824\n",
      "Epoch 21/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.6446 - acc: 0.2944 - val_loss: 1.5985 - val_acc: 0.2500\n",
      "Epoch 22/160\n",
      "608/608 [==============================] - 16s 27ms/step - loss: 1.4942 - acc: 0.3750 - val_loss: 1.4700 - val_acc: 0.4265\n",
      "Epoch 23/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 1.3594 - acc: 0.4326 - val_loss: 1.3530 - val_acc: 0.4265\n",
      "Epoch 24/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.4828 - acc: 0.3898 - val_loss: 1.4539 - val_acc: 0.4118\n",
      "Epoch 25/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.3444 - acc: 0.4539 - val_loss: 1.3180 - val_acc: 0.4706\n",
      "Epoch 26/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 1.2917 - acc: 0.4720 - val_loss: 1.2876 - val_acc: 0.3824\n",
      "Epoch 27/160\n",
      "608/608 [==============================] - 16s 26ms/step - loss: 1.3058 - acc: 0.4622 - val_loss: 1.3804 - val_acc: 0.3529\n",
      "Epoch 28/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.3155 - acc: 0.4605 - val_loss: 1.3129 - val_acc: 0.3971\n",
      "Epoch 29/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.3114 - acc: 0.4934 - val_loss: 1.4069 - val_acc: 0.4706\n",
      "Epoch 30/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 1.3007 - acc: 0.4655 - val_loss: 1.2588 - val_acc: 0.4853\n",
      "Epoch 31/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 1.2535 - acc: 0.5148 - val_loss: 1.3247 - val_acc: 0.4265\n",
      "Epoch 32/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.1948 - acc: 0.5132 - val_loss: 1.2013 - val_acc: 0.4706\n",
      "Epoch 33/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.1569 - acc: 0.5428 - val_loss: 1.1938 - val_acc: 0.4706\n",
      "Epoch 34/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 1.1021 - acc: 0.5461 - val_loss: 1.1509 - val_acc: 0.5147\n",
      "Epoch 35/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.0989 - acc: 0.5296 - val_loss: 1.1898 - val_acc: 0.4118\n",
      "Epoch 36/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.1494 - acc: 0.5444 - val_loss: 1.5121 - val_acc: 0.4118\n",
      "Epoch 37/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.0355 - acc: 0.5757 - val_loss: 1.1090 - val_acc: 0.5294\n",
      "Epoch 38/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.1257 - acc: 0.5313 - val_loss: 1.2752 - val_acc: 0.4559\n",
      "Epoch 39/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.1114 - acc: 0.5444 - val_loss: 1.1401 - val_acc: 0.5000\n",
      "Epoch 40/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.0077 - acc: 0.5905 - val_loss: 1.4137 - val_acc: 0.5588\n",
      "Epoch 41/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 1.0426 - acc: 0.5691 - val_loss: 1.0960 - val_acc: 0.5441\n",
      "Epoch 42/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 0.8946 - acc: 0.6497 - val_loss: 1.0668 - val_acc: 0.5735\n",
      "Epoch 43/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.8600 - acc: 0.6562 - val_loss: 1.0518 - val_acc: 0.5882\n",
      "Epoch 44/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.8745 - acc: 0.6464 - val_loss: 1.0518 - val_acc: 0.5882\n",
      "Epoch 45/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.7713 - acc: 0.7023 - val_loss: 1.0429 - val_acc: 0.6176\n",
      "Epoch 46/160\n",
      "608/608 [==============================] - 14s 22ms/step - loss: 0.8140 - acc: 0.6776 - val_loss: 1.0593 - val_acc: 0.6324\n",
      "Epoch 47/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.8105 - acc: 0.6711 - val_loss: 1.0583 - val_acc: 0.5441\n",
      "Epoch 48/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.8135 - acc: 0.6513 - val_loss: 1.0644 - val_acc: 0.5588\n",
      "Epoch 49/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.8487 - acc: 0.6530 - val_loss: 1.0511 - val_acc: 0.5441\n",
      "Epoch 50/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.7908 - acc: 0.6661 - val_loss: 1.0576 - val_acc: 0.5588\n",
      "Epoch 51/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.8142 - acc: 0.6645 - val_loss: 1.0406 - val_acc: 0.6324\n",
      "Epoch 52/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.8095 - acc: 0.6743 - val_loss: 1.0419 - val_acc: 0.5735\n",
      "Epoch 53/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.7755 - acc: 0.7072 - val_loss: 1.0521 - val_acc: 0.5735\n",
      "Epoch 54/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.8228 - acc: 0.6645 - val_loss: 1.0444 - val_acc: 0.5735\n",
      "Epoch 55/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.7435 - acc: 0.6776 - val_loss: 1.0494 - val_acc: 0.5882\n",
      "Epoch 56/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.7706 - acc: 0.6941 - val_loss: 1.0504 - val_acc: 0.5882\n",
      "Epoch 57/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 0.7641 - acc: 0.6859 - val_loss: 1.0420 - val_acc: 0.5882\n",
      "Epoch 58/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.7133 - acc: 0.7155 - val_loss: 1.0547 - val_acc: 0.5441\n",
      "Epoch 59/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.7419 - acc: 0.7007 - val_loss: 1.0841 - val_acc: 0.5882\n",
      "Epoch 60/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 0.7661 - acc: 0.6727 - val_loss: 1.0459 - val_acc: 0.6029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 0.7277 - acc: 0.7188 - val_loss: 1.0447 - val_acc: 0.5882\n",
      "Epoch 62/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6865 - acc: 0.7286 - val_loss: 1.0558 - val_acc: 0.6176\n",
      "Epoch 63/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.6971 - acc: 0.7204 - val_loss: 1.0640 - val_acc: 0.6029\n",
      "Epoch 64/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.7837 - acc: 0.6891 - val_loss: 1.0358 - val_acc: 0.6029\n",
      "Epoch 65/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.7403 - acc: 0.7237 - val_loss: 1.0523 - val_acc: 0.6029\n",
      "Epoch 66/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.7792 - acc: 0.6941 - val_loss: 1.0693 - val_acc: 0.5735\n",
      "Epoch 67/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.6855 - acc: 0.7270 - val_loss: 1.0723 - val_acc: 0.6029\n",
      "Epoch 68/160\n",
      "608/608 [==============================] - 18s 29ms/step - loss: 0.7042 - acc: 0.7253 - val_loss: 1.0770 - val_acc: 0.5882\n",
      "Epoch 69/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6421 - acc: 0.7566 - val_loss: 1.0695 - val_acc: 0.5735\n",
      "Epoch 70/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6940 - acc: 0.7418 - val_loss: 1.0966 - val_acc: 0.5882\n",
      "Epoch 71/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.7114 - acc: 0.7171 - val_loss: 1.1430 - val_acc: 0.5735\n",
      "Epoch 72/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.7039 - acc: 0.7204 - val_loss: 1.0811 - val_acc: 0.5882\n",
      "Epoch 73/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 0.6280 - acc: 0.7434 - val_loss: 1.1313 - val_acc: 0.5882\n",
      "Epoch 74/160\n",
      "608/608 [==============================] - 15s 25ms/step - loss: 0.7112 - acc: 0.7352 - val_loss: 1.0632 - val_acc: 0.6176\n",
      "Epoch 75/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6787 - acc: 0.7204 - val_loss: 1.0528 - val_acc: 0.6029\n",
      "Epoch 76/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6210 - acc: 0.7812 - val_loss: 1.1389 - val_acc: 0.5882\n",
      "Epoch 77/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6340 - acc: 0.7385 - val_loss: 1.0941 - val_acc: 0.6176\n",
      "Epoch 78/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6537 - acc: 0.7467 - val_loss: 1.1235 - val_acc: 0.5882\n",
      "Epoch 79/160\n",
      "608/608 [==============================] - 14s 22ms/step - loss: 0.6739 - acc: 0.7352 - val_loss: 1.0816 - val_acc: 0.6029\n",
      "Epoch 80/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6515 - acc: 0.7500 - val_loss: 1.0422 - val_acc: 0.6324\n",
      "Epoch 81/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.5937 - acc: 0.7763 - val_loss: 1.0392 - val_acc: 0.6029\n",
      "Epoch 82/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6445 - acc: 0.7418 - val_loss: 1.0487 - val_acc: 0.6176\n",
      "Epoch 83/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6289 - acc: 0.7500 - val_loss: 1.0441 - val_acc: 0.6029\n",
      "Epoch 84/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6013 - acc: 0.7714 - val_loss: 1.0406 - val_acc: 0.6029\n",
      "Epoch 85/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.5854 - acc: 0.7813 - val_loss: 1.0422 - val_acc: 0.6029\n",
      "Epoch 86/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.6063 - acc: 0.7664 - val_loss: 1.0382 - val_acc: 0.5882\n",
      "Epoch 87/160\n",
      "608/608 [==============================] - 15s 24ms/step - loss: 0.6139 - acc: 0.7549 - val_loss: 1.0511 - val_acc: 0.5882\n",
      "Epoch 88/160\n",
      "608/608 [==============================] - 16s 26ms/step - loss: 0.6053 - acc: 0.7615 - val_loss: 1.0494 - val_acc: 0.5882\n",
      "Epoch 89/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.5945 - acc: 0.7862 - val_loss: 1.0516 - val_acc: 0.5882\n",
      "Epoch 90/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.6272 - acc: 0.7664 - val_loss: 1.0557 - val_acc: 0.6029\n",
      "Epoch 91/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.6353 - acc: 0.7467 - val_loss: 1.0595 - val_acc: 0.6029\n",
      "Epoch 92/160\n",
      "608/608 [==============================] - 16s 26ms/step - loss: 0.5767 - acc: 0.7648 - val_loss: 1.0604 - val_acc: 0.6029\n",
      "Epoch 93/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6071 - acc: 0.7500 - val_loss: 1.0542 - val_acc: 0.6029\n",
      "Epoch 94/160\n",
      "608/608 [==============================] - 14s 24ms/step - loss: 0.5683 - acc: 0.7747 - val_loss: 1.0562 - val_acc: 0.6029\n",
      "Epoch 95/160\n",
      "608/608 [==============================] - 14s 23ms/step - loss: 0.6073 - acc: 0.7533 - val_loss: 1.0549 - val_acc: 0.6029\n",
      "Epoch 96/160\n",
      "420/608 [===================>..........] - ETA: 4s - loss: 0.5567 - acc: 0.7881"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-49aa4fb16607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchange_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchange_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_path = './weights/weights_best_6.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path,monitor='val_loss',verbose=0,period=1,save_best_only=True)\n",
    "change_lr = LearningRateScheduler(scheduler)\n",
    "history = seq_m.fit(fit_features,train_labels, nb_epoch=160, batch_size=20, verbose=1,validation_data=(predict_features,test_labels), callbacks=[checkpoint,change_lr])\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_m.save('60.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_m.save('60.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import sys\n",
    "\n",
    "def disp_to_term(msg):\n",
    "    sys.stdout.write(msg + '\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def load_pickle(filename):\n",
    "    try:\n",
    "        p = open(filename, 'r')\n",
    "    except IOError:\n",
    "        print(\"Pickle file cannot be opened.\")\n",
    "        return None\n",
    "    try:\n",
    "        picklelicious = pk.load(p)\n",
    "    except ValueError:\n",
    "        print('load_pickle failed once, trying again')\n",
    "        p.close()\n",
    "        p = open(filename, 'r')\n",
    "        picklelicious = pk.load(p)\n",
    "\n",
    "    p.close()\n",
    "    return picklelicious\n",
    "\n",
    "def save_pickle(data_object, filename):\n",
    "    pickle_file = open(filename, 'w')\n",
    "    pk.dump(data_object, pickle_file)\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, nc, ngf, ndf, latent_variable_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.ngf = ngf\n",
    "        self.ndf = ndf\n",
    "        self.latent_variable_size = latent_variable_size\n",
    "\n",
    "        # encoder\n",
    "        self.e1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "\n",
    "        self.e2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
    "\n",
    "        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
    "\n",
    "        self.e4 = nn.Conv2d(ndf*4, ndf*8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.e5 = nn.Conv2d(ndf*8, ndf*8, 4, 2, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(ndf*8)\n",
    "\n",
    "        self.fc1 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "        self.fc2 = nn.Linear(ndf*8*4*4, latent_variable_size)\n",
    "\n",
    "        # decoder\n",
    "        self.d1 = nn.Linear(latent_variable_size, ngf*8*2*4*4)\n",
    "\n",
    "        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd1 = nn.ReplicationPad2d(1)\n",
    "        self.d2 = nn.Conv2d(ngf*8*2, ngf*8, 3, 1)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8, 1.e-3)\n",
    "\n",
    "        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd2 = nn.ReplicationPad2d(1)\n",
    "        self.d3 = nn.Conv2d(ngf*8, ngf*4, 3, 1)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*4, 1.e-3)\n",
    "\n",
    "        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd3 = nn.ReplicationPad2d(1)\n",
    "        self.d4 = nn.Conv2d(ngf*4, ngf*2, 3, 1)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*2, 1.e-3)\n",
    "\n",
    "        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd4 = nn.ReplicationPad2d(1)\n",
    "        self.d5 = nn.Conv2d(ngf*2, ngf, 3, 1)\n",
    "        self.bn9 = nn.BatchNorm2d(ngf, 1.e-3)\n",
    "\n",
    "        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.pd5 = nn.ReplicationPad2d(1)\n",
    "        self.d6 = nn.Conv2d(ngf, nc, 3, 1)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n",
    "        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n",
    "        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n",
    "        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n",
    "        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n",
    "        h5 = h5.view(-1, self.ndf*8*4*4)\n",
    "\n",
    "        return self.fc1(h5), self.fc2(h5)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if 1:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h1 = self.relu(self.d1(z))\n",
    "        h1 = h1.view(-1, self.ngf*8*2, 4, 4)\n",
    "        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n",
    "        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n",
    "        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n",
    "        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n",
    "\n",
    "        return self.sigmoid(self.d6(self.pd5(self.up5(h5))))\n",
    "\n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(z)\n",
    "        return res, mu, logvar\n",
    "\n",
    "model = VAE(nc=3, ngf=128, ndf=128, latent_variable_size=500)\n",
    "model.load_state_dict(torch.load('/home/apletea/Downloads/sign/neunets/video_classification/weights/cpu_Epoch_28_Train_loss_25425.9503_Test_loss_25172.4120(3).pth'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(nc=3, ngf=128, ndf=128, latent_variable_size=500)\n",
    "model.load_state_dict(torch.load('/home/apletea/Downloads/sign/neunets/video_classification/weights/cpu_Epoch_28_Train_loss_25425.9503_Test_loss_25172.4120(3).pth'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "totensor = transforms.ToTensor()\n",
    "img = cv2.imread('/home/apletea/Pictures/Screenshot from 2018-10-25 00-42-35.png')\n",
    "img = cv2.resize(img, (128,128))\n",
    "print(img.shape)\n",
    "img = np.transpose(img,(2,0,1))\n",
    "img = np.expand_dims(img, axis=0) / 255\n",
    "#mat = totensor(img)\n",
    "b = model.encode(torch.Tensor(img).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 500)\n"
     ]
    }
   ],
   "source": [
    "a = b[1].cpu().detach().numpy()\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingNearest2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "img,z,mean = model.forward(torch.Tensor(img).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = img.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = a * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.transpose(img,(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('out.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
